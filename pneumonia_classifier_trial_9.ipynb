{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pneumonia classifier trial 9 ",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_zYdsqJ2_Ar"
      },
      "source": [
        "! pip install -q kaggle\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8XtgY6m3GES"
      },
      "source": [
        "!kaggle datasets download -d pcbreviglieri/pneumonia-xray-images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bo2u1G7H45_r"
      },
      "source": [
        "import zipfile\n",
        "zf = \"/content/pneumonia-xray-images.zip\"\n",
        "target_dir = \"/content/dataset/cnn/pneumonia_revamped\"\n",
        "zfile = zipfile.ZipFile(zf)\n",
        "zfile.extractall(target_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXXc6ubp5Xw_"
      },
      "source": [
        "#Some Basic Imports\n",
        "import matplotlib.pyplot as plt #For Visualization\n",
        "import numpy as np              #For handling arrays\n",
        "import pandas as pd             # For handling data\n",
        "#Define Directories for train, test & Validation Set\n",
        "train_path = '/content/dataset/cnn/pneumonia_revamped/train'\n",
        "test_path = '/content/dataset/cnn/pneumonia_revamped/test'\n",
        "valid_path = '/content/dataset/cnn/pneumonia_revamped/val'\n",
        "#Define some often used standard parameters\n",
        "#The batch refers to the number of training examples utilized in one #iteration\n",
        "batch_size = 16 \n",
        "#The dimension of the images we are going to define is 500x500 img_height = 500\n",
        "img_width = 500\n",
        "img_height = 500\n",
        "#The dimension size of 500 or more than 500 with batch size greater than 16 may result in a crash as the RAM gets completely used in such cases. A lower dimension size with greater batch size is one of the options to try."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgQUJQVm50nI"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "# Create Image Data Generator for Train Set\n",
        "image_gen = ImageDataGenerator(\n",
        "                                  rescale = 1./255,\n",
        "                                  shear_range = 0.2,\n",
        "                                  zoom_range = 0.2,\n",
        "                                  horizontal_flip = True,          \n",
        "                               )\n",
        "# Create Image Data Generator for Test/Validation Set\n",
        "test_data_gen = ImageDataGenerator(rescale = 1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7qzMc1h6A7F"
      },
      "source": [
        "train = image_gen.flow_from_directory(\n",
        "      train_path,\n",
        "      target_size=(img_height, img_width),\n",
        "      color_mode='grayscale',\n",
        "      class_mode='binary',\n",
        "      batch_size=batch_size\n",
        "      )\n",
        "test = test_data_gen.flow_from_directory(\n",
        "      test_path,\n",
        "      target_size=(img_height, img_width),\n",
        "      color_mode='grayscale',\n",
        "      shuffle=False, \n",
        "#setting shuffle as False just so we can later compare it with predicted values without having indexing problem \n",
        "      class_mode='binary',\n",
        "      batch_size=batch_size\n",
        "      )\n",
        "valid = test_data_gen.flow_from_directory(\n",
        "      valid_path,\n",
        "      target_size=(img_height, img_width),\n",
        "      color_mode='grayscale',\n",
        "      class_mode='binary', \n",
        "      batch_size=batch_size\n",
        "      )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FR6s85WS6c9T"
      },
      "source": [
        "plt.figure(figsize=(12, 12))\n",
        "for i in range(0, 10):\n",
        "    plt.subplot(2, 5, i+1)\n",
        "    for X_batch, Y_batch in train:\n",
        "        image = X_batch[0]        \n",
        "        dic = {0:'NORMAL', 1:'PNEUMONIA'}\n",
        "        plt.title(dic.get(Y_batch[0]))\n",
        "        plt.axis('off')\n",
        "        plt.imshow(np.squeeze(image),cmap='gray',interpolation='nearest')\n",
        "        break\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZCqKiEH6yrb"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Conv2D,Flatten,MaxPooling2D\n",
        "from tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGXPlkJs7OM4"
      },
      "source": [
        "cnn = Sequential()\n",
        "cnn.add(Conv2D(32, (3, 3), activation=\"relu\", input_shape=(img_width, img_height, 1)))\n",
        "cnn.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "cnn.add(Conv2D(32, (3, 3), activation=\"relu\", input_shape=(img_width, img_height, 1)))\n",
        "cnn.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "cnn.add(Conv2D(32, (3, 3), activation=\"relu\", input_shape=(img_width, img_height, 1)))\n",
        "cnn.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "cnn.add(Conv2D(64, (3, 3), activation=\"relu\", input_shape=(img_width, img_height, 1)))\n",
        "cnn.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "cnn.add(Conv2D(64, (3, 3), activation=\"relu\", input_shape=(img_width, img_height, 1)))\n",
        "cnn.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "cnn.add(Flatten())\n",
        "cnn.add(Dense(activation = 'relu', units = 128))\n",
        "cnn.add(Dense(activation = 'relu', units = 64))\n",
        "cnn.add(Dense(activation = 'sigmoid', units = 1))\n",
        "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bA1fpn0n7kmv"
      },
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(cnn,show_shapes=True, show_layer_names=True, rankdir='TB', expand_nested=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hOL-lGA8JeU"
      },
      "source": [
        "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=3)\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience = 2, verbose=1,factor=0.3, min_lr=0.000001)\n",
        "callbacks_list = [ early, learning_rate_reduction]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ro2L0QFZ8XJV"
      },
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "weights = compute_class_weight('balanced', np.unique(train.classes), train.classes)\n",
        "cw = dict(zip( np.unique(train.classes), weights))\n",
        "print(cw)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhaMbr1J8iO_"
      },
      "source": [
        "cnn.fit(train,epochs=25, validation_data=valid, class_weight=cw, callbacks=callbacks_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fun5Z9lKWjS9"
      },
      "source": [
        "fp = \"/content/drive/MyDrive/cnn_pneu_vamp_model.h5\"\n",
        "cnn.save(fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04anlevt8pUn"
      },
      "source": [
        "pd.DataFrame(cnn.history.history).plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4d25EZuf-DKX"
      },
      "source": [
        "test_accu = cnn.evaluate(test)\n",
        "print('The testing accuracy is :',test_accu[1]*100, '%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-47oE9Mx-Ebn"
      },
      "source": [
        "preds = cnn.predict(test,verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1bgmxiG-IQn"
      },
      "source": [
        "predictions = preds.copy()\n",
        "predictions[predictions <= 0.5] = 0\n",
        "predictions[predictions > 0.5] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PS3OFwxM-n34"
      },
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "cm = pd.DataFrame(data=confusion_matrix(test.classes, predictions, labels=[0, 1]),index=[\"Actual Normal\", \"Actual Pneumonia\"],\n",
        "columns=[\"Predicted Normal\", \"Predicted Pneumonia\"])\n",
        "import seaborn as sns\n",
        "sns.heatmap(cm,annot=True,fmt=\"d\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jPQbWsI-pCz"
      },
      "source": [
        "print(classification_report(y_true=test.classes,y_pred=predictions,target_names =['NORMAL','PNEUMONIA']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQ4vtpux-wxy"
      },
      "source": [
        "test.reset()\n",
        "x=np.concatenate([test.next()[0] for i in range(test.__len__())])\n",
        "y=np.concatenate([test.next()[1] for i in range(test.__len__())])\n",
        "print(x.shape)\n",
        "print(y.shape)\n",
        "#this little code above extracts the images from test Data iterator without shuffling the sequence\n",
        "# x contains image array and y has labels \n",
        "dic = {0:'NORMAL', 1:'PNEUMONIA'}\n",
        "plt.figure(figsize=(20,20))\n",
        "for i in range(0+228, 9+228):\n",
        "  plt.subplot(3, 3, (i-228)+1)\n",
        "  if preds[i, 0] >= 0.5: \n",
        "      out = ('{:.2%} probability of being Pneumonia case'.format(preds[i][0]))\n",
        "      \n",
        "      \n",
        "  else: \n",
        "      out = ('{:.2%} probability of being Normal case'.format(1-preds[i][0]))\n",
        "\n",
        "\n",
        "plt.title(out+\"\\n Actual case : \"+ dic.get(y[i]))    \n",
        "plt.imshow(np.squeeze(x[i]))\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3IEJTWmPK5j"
      },
      "source": [
        "test.reset()\n",
        "x=np.concatenate([test.next()[0] for i in range(test.__len__())])\n",
        "y=np.concatenate([test.next()[1] for i in range(test.__len__())])\n",
        "print(x.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHdyEvr_BSf2"
      },
      "source": [
        "# Testing with my own Chest X-Ray\n",
        "p_path = '/content/drive/MyDrive/images/00000047_005.png'\n",
        "from tensorflow.keras.preprocessing import image\n",
        "hardik_img = image.load_img(p_path, target_size=(500, 500),color_mode='grayscale')\n",
        "# Preprocessing the image\n",
        "pp_hardik_img = image.img_to_array(hardik_img)\n",
        "pp_hardik_img = pp_hardik_img/255\n",
        "pp_hardik_img = np.expand_dims(pp_hardik_img, axis=0)\n",
        "#predict\n",
        "hardik_preds= cnn.predict(pp_hardik_img)\n",
        "#print\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.axis('off')\n",
        "if hardik_preds>= 0.5: \n",
        "    out = ('I am {:.2%} percent confirmed that this is a Pneumonia case'.format(hardik_preds[0][0]))\n",
        "    \n",
        "else: \n",
        "    out = ('I am {:.2%} percent confirmed that this is a Normal case'.format(1-hardik_preds[0][0]))\n",
        "plt.title(\"Hardik's Chest X-Ray\\n\"+out)  \n",
        "plt.imshow(np.squeeze(pp_hardik_img))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhCrkeI6PPyf"
      },
      "source": [
        "dic = {0:'NORMAL', 1:'PNEUMONIA'}\n",
        "plt.figure(figsize=(20,20))\n",
        "for i in range(0+228, 9+228):\n",
        "  plt.subplot(3, 3, (i-228)+1)\n",
        "  if preds[i, 0] >= 0.5: \n",
        "      out = ('{:.2%} probability of being Pneumonia case'.format(preds[i][0]))\n",
        "      \n",
        "      \n",
        "  else: \n",
        "      out = ('{:.2%} probability of being Normal case'.format(1-preds[i][0]))\n",
        "      \n",
        "      \n",
        "\n",
        "  plt.title(out+\"\\n Actual case : \"+ dic.get(y[i]))    \n",
        "  plt.imshow(np.squeeze(x[i]))\n",
        "  plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0PFtwIBOzSX"
      },
      "source": [
        "'''import plotly.graph_objects as go\n",
        "fig = go.Figure( go.Scatter(y=y ) )\n",
        "fig.show()'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdN3o9SPPaXx"
      },
      "source": [
        "'''import plotly.graph_objects as go\n",
        "fig = go.Figure( go.Scatter(y=predictions[:,0] ) )\n",
        "fig.show()'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyobG9OUPfcz"
      },
      "source": [
        "# Testing with my own Chest X-Ray\n",
        "hardik_path = '/content/dataset/cnn/pneumonia_revamped/test/normal/IM-0001-0001.jpeg'\n",
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "hardik_img = image.load_img(hardik_path, target_size=(500, 500),color_mode='grayscale')\n",
        "\n",
        "# Preprocessing the image\n",
        "pp_hardik_img = image.img_to_array(hardik_img)\n",
        "pp_hardik_img = pp_hardik_img/255\n",
        "pp_hardik_img = np.expand_dims(pp_hardik_img, axis=0)\n",
        "\n",
        "#predict\n",
        "hardik_preds= cnn.predict(pp_hardik_img)\n",
        "\n",
        "#print\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.axis('off')\n",
        "if hardik_preds>= 0.5: \n",
        "    out = ('I am {:.2%} percent probability that this is a Pneumonia case'.format(hardik_preds[0][0]))\n",
        "    \n",
        "else: \n",
        "    out = ('I am {:.2%} percent probability that this is a Normal case'.format(1-hardik_preds[0][0]))\n",
        "    \n",
        "\n",
        "plt.title(\"Hardik's Chest X-Ray\\n\"+out)  \n",
        "plt.imshow(np.squeeze(pp_hardik_img))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GudBdTlYQBXA"
      },
      "source": [
        "!pip install -q streamlit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U367GMvOQHea"
      },
      "source": [
        "!pip install h5py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynw804l8QRmm"
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZD7ti7dQfW4"
      },
      "source": [
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9iBX_ssQi0K"
      },
      "source": [
        "%%writefile webapp.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image \n",
        "from tensorflow.keras.models import load_model\n",
        "import tensorflow as tf\n",
        " \n",
        "from tempfile import NamedTemporaryFile\n",
        "from tensorflow.keras.preprocessing import image \n",
        "\n",
        "@st.cache(allow_output_mutation=True)\n",
        "\n",
        "def loading_model():\n",
        "  fp = \"/content/drive/MyDrive/cnn_pneu_vamp_model.h5\"\n",
        "  model_loader = load_model(fp)\n",
        "  return model_loader\n",
        "\n",
        "cnn = loading_model()\n",
        "st.write(\"\"\"Chest X-Ray Classifier for diagnosing Pneumonia\"\"\")\n",
        "st.markdown(' Diagnosing Pneumonia 🩺')\n",
        "st.markdown(\"This model uses a convolutional neural network to classify  Chest x-rays.\")\n",
        "st.markdown(\"The model achieved an accuracy of ~91% on a testset of more than 6000 lung x-rays\")\n",
        "st.markdown(\"*Disclaimer: For training porpuse only*\")\n",
        "\n",
        "st.sidebar.write('''\n",
        "                # Data Acknowledgements\n",
        "                [Open Source Dataset](https://www.kaggle.com/pcbreviglieri/pneumonia-xray-images)\n",
        "                ## License\n",
        "                [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/)\n",
        "                ## Citation \n",
        "                [Kermany et al., Identifying Medical Diagnoses and Treatable Diseases by Image-Based Deep Learning 2018, Cell 172, 1122–1131 February 22, 2018 ª 2018 Elsevier Inc.https://doi.org/10.1016/j.cell.2018.02.010]\n",
        "                ''')\n",
        "st.markdown(\n",
        "    \"\"\"\n",
        "    <style>\n",
        "    .reportview-container {\n",
        "        background: url(\"/content/drive/MyDrive/3.jpg\")\n",
        "    }\n",
        "   .sidebar .sidebar-content {\n",
        "        background: url(\"/content/drive/MyDrive/R (1).jpg\")\n",
        "    }\n",
        "    </style>\n",
        "    \"\"\",\n",
        "    unsafe_allow_html=True\n",
        ")\n",
        "temp = st.file_uploader(\"Upload X-Ray Image\")\n",
        "\n",
        "buffer = temp\n",
        "temp_file = NamedTemporaryFile(delete=False)\n",
        "if buffer:\n",
        "    temp_file.write(buffer.getvalue())\n",
        "    st.write(image.load_img(temp_file.name))\n",
        "\n",
        "\n",
        "if buffer is None:\n",
        "  st.text(\"Oops! that doesn't look like an image. Try again.\")\n",
        "\n",
        "else:\n",
        "  hardik_img = image.load_img(temp_file.name, target_size=(500, 500),color_mode='grayscale')\n",
        "  # Preprocessing the image\n",
        "  pp_hardik_img = image.img_to_array(hardik_img)\n",
        "  pp_hardik_img = pp_hardik_img/255\n",
        "  pp_hardik_img = np.expand_dims(pp_hardik_img, axis=0)\n",
        "  #predict\n",
        "  hardik_preds= cnn.predict(pp_hardik_img)\n",
        "  if hardik_preds>= 0.5:\n",
        "    out = ('I am {:.2%} percent confirmed that this is a Pneumonia case'.format(hardik_preds[0][0]))\n",
        "  \n",
        "  else: \n",
        "    out = ('I am {:.2%} percent confirmed that this is a Normal case'.format(1-hardik_preds[0][0]))\n",
        "    st.success(out)\n",
        "    df = pd.DataFrame(data= hardik_preds[0], index=[ 'Pneumonic', 'Normal'], columns=['confidence'])\n",
        "    st.write(f'''### 🦠 Confidence - Pneumonic: **{np.round(hardik_preds[0][2]*100, 3)}%**''')\n",
        "    st.write(f'''### 👍 Confidence - Normal: **{np.round(hardik_preds[0][1]*100, 3)}%**''')\n",
        "    st.write('')\n",
        "    st.bar_chart(df)\n",
        "  \n",
        "image = Image.open(temp)\n",
        "st.image(image,use_column_width=True)\n",
        "          \n",
        "            \n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PuRuLU-v51a"
      },
      "source": [
        "%%writefile webapp.py\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "from PIL import Image \n",
        "from tensorflow.keras.models import load_model\n",
        "import tensorflow as tf\n",
        " \n",
        "from tempfile import NamedTemporaryFile\n",
        "from tensorflow.keras.preprocessing import image \n",
        "\n",
        "st.set_option('deprecation.showfileUploaderEncoding', False)\n",
        "@st.cache(allow_output_mutation=True)\n",
        "\n",
        "def loading_model():\n",
        "  fp = \"/content/drive/MyDrive/cnn_pneu_vamp_model.h5\"\n",
        "  model_loader = load_model(fp)\n",
        "  return model_loader\n",
        "\n",
        "cnn = loading_model()\n",
        "st.write(\"\"\"\n",
        "# X-Ray Classification (Pneumonia/Normal)\n",
        "\"\"\")\n",
        "st.write(\"\"\"Chest X-Ray Classifier for diagnosing Pneumonia\"\"\")\n",
        "st.markdown(' Diagnosing Pneumonia 🩺')\n",
        "st.markdown(\"This model uses a convolutional neural network to classify  Chest x-rays.\")\n",
        "st.markdown(\"The model achieved an accuracy of ~91% on a testset of more than 6000 lung x-rays\")\n",
        "st.markdown(\"*Disclaimer: For training porpuse only*\")\n",
        "\n",
        "st.sidebar.write('''\n",
        "                # Data Acknowledgements\n",
        "                [Open Source Dataset](https://www.kaggle.com/pcbreviglieri/pneumonia-xray-images)\n",
        "                ## License\n",
        "                [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/)\n",
        "                ## Citation \n",
        "                [Kermany et al., Identifying Medical Diagnoses and Treatable Diseases by Image-Based Deep Learning 2018, Cell 172, 1122–1131 February 22, 2018 ª 2018 Elsevier Inc.https://doi.org/10.1016/j.cell.2018.02.010]\n",
        "                ''')\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "temp = st.file_uploader(\"Upload X-Ray Image\")\n",
        "\n",
        "buffer = temp\n",
        "temp_file = NamedTemporaryFile(delete=False)\n",
        "if buffer:\n",
        "    temp_file.write(buffer.getvalue())\n",
        "    st.write(image.load_img(temp_file.name))\n",
        "\n",
        "\n",
        "if buffer is None:\n",
        "  st.text(\"Oops! that doesn't look like an image. Try again.\")\n",
        "\n",
        "else:\n",
        "\n",
        " \n",
        "\n",
        "  hardik_img = image.load_img(temp_file.name, target_size=(500, 500),color_mode='grayscale')\n",
        "\n",
        "  # Preprocessing the image\n",
        "  pp_hardik_img = image.img_to_array(hardik_img)\n",
        "  pp_hardik_img = pp_hardik_img/255\n",
        "  pp_hardik_img = np.expand_dims(pp_hardik_img, axis=0)\n",
        "\n",
        "  #predict\n",
        "  hardik_preds= cnn.predict(pp_hardik_img)\n",
        "  if hardik_preds>= 0.5:\n",
        "    out = ('I am {:.2%} percent confirmed that this is a Pneumonia case'.format(hardik_preds[0][0]))\n",
        "  \n",
        "  else: \n",
        "    out = ('I am {:.2%} percent confirmed that this is a Normal case'.format(1-hardik_preds[0][0]))\n",
        "\n",
        "  st.success(out)\n",
        "  \n",
        "  image = Image.open(temp)\n",
        "  st.image(image,use_column_width=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9is-9NDQqgA"
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 8501 &')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9cZxYX2Q4--"
      },
      "source": [
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    'import sys, json; print(\"Execute the next cell and the go to the following URL: \" +json.load(sys.stdin)[\"tunnels\"][0][\"public_url\"])'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AALjhO21sVgp"
      },
      "source": [
        "!streamlit run /content/webapp.py\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pqVZ14p7lpH"
      },
      "source": [
        "!mkdir Image-Classification-App\n",
        "!cd Image-Classification-App"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RV7ITbFXOcgW"
      },
      "source": [
        "!virtualenv Img-Class-Env"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJ85F254PK-Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}